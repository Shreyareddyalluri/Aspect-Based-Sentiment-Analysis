# -*- coding: utf-8 -*-
"""SA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J-5Ebx-3q8mg4Urkh4EmdESSRHCPO3JE
"""

from google.colab import drive
drive.mount('/content/gdrive')

import pandas as pd
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from sklearn.feature_extraction.text import CountVectorizer

# Download the VADER lexicon
nltk.download('vader_lexicon')

# Load the CSV file
data = pd.read_csv('/content/gdrive/MyDrive/Clean_Flipkart_Product.csv')

# Initialize the sentiment analyzer
sia = SentimentIntensityAnalyzer()

# Rest of the code...

import pandas as pd

# Load the CSV file
data = pd.read_csv('/content/gdrive/MyDrive/Clean_Flipkart_Product.csv')

# Get the column names
columns = data.columns.tolist()

# Print the column names
print(columns)

import pandas as pd
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from sklearn.feature_extraction.text import CountVectorizer

# Load the CSV file
data = pd.read_csv('/content/gdrive/MyDrive/Clean_Flipkart_Product.csv')
# Initialize the sentiment analyzer
sia = SentimentIntensityAnalyzer()

# Define the aspect terms you want to analyze
aspects = ['phone', 'camera', 'battery', 'delivery']

# Function to extract the sentiment for each aspect
def extract_sentiment(text):
    sentiment = sia.polarity_scores(text)
    return sentiment['compound']

# Function to analyze the sentiment of the reviews for each aspect
def analyze_reviews(reviews):
    # Tokenize the reviews
    nltk.download('punkt')
    tokenized_reviews = [nltk.word_tokenize(review.lower()) for review in reviews]

    # Initialize a count vectorizer
    vectorizer = CountVectorizer(vocabulary=aspects)

    # Convert the tokenized reviews to a matrix of token counts
    review_matrix = vectorizer.transform([' '.join(tokens) for tokens in tokenized_reviews])

    # Calculate the sentiment for each aspect
    aspect_sentiments = {}
    for i, aspect in enumerate(aspects):
        aspect_sentiments[aspect] = review_matrix[:, i].multiply([extract_sentiment(review) for review in reviews]).sum()

    return aspect_sentiments

# Function to classify the sentiment as positive, negative, or neutral
def classify_sentiment(sentiment):
    if sentiment > 0:
        return 'Positive'
    elif sentiment < 0:
        return 'Negative'
    else:
        return 'Neutral'

# Extract the reviews from the CSV file
reviews = data['clean_review'].tolist() + data['clean_review2'].tolist()

# Analyze the sentiment for each aspect
aspect_sentiments = analyze_reviews(reviews)

# Classify the sentiment of each aspect
aspect_classifications = {aspect: classify_sentiment(sentiment) for aspect, sentiment in aspect_sentiments.items()}

# Print the sentiment classification for each aspect
for aspect, classification in aspect_classifications.items():
    print(f"Aspect: {aspect}\t Classification: {classification}")

import nltk
from nltk.sentiment import SentimentIntensityAnalyzer

# Initialize the sentiment analyzer
sia = SentimentIntensityAnalyzer()

# Function to classify the sentiment as positive, negative, or neutral
def classify_sentiment(sentiment):
    if sentiment > 0:
        return 'Positive'
    elif sentiment < 0:
        return 'Negative'
    else:
        return 'Neutral'

# Function to perform sentiment analysis on a given review
def perform_sentiment_analysis(review):
    sentiment = sia.polarity_scores(review)
    compound_score = sentiment['compound']
    classification = classify_sentiment(compound_score)
    return classification

# Test with a review
review = "Thise is very nice mobile ...I like it very much ..... delivery is also fast in lockdown ...I am very happy to it .thank you mi Redmi. . and back camera quality is very evil but rear camera is a large bit high. But value for money."
classification = perform_sentiment_analysis(review)

# Print the sentiment classification
print(f"Review: {review}")
print(f"Classification: {classification}")